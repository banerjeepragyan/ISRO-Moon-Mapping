{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIz_Gm1arXEI"
   },
   "source": [
    "**Submission Notebook**\n",
    "\n",
    "This notebook serves as a guide to run inference on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEZ_utZowvyg"
   },
   "source": [
    "**Installing and Importing Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgtZj77Cvw42",
    "outputId": "b40fdd77-b053-4e2e-ff10-1ce30f7c7f5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: patchify in /home/akshat/anaconda3/lib/python3.9/site-packages (0.2.3)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/akshat/anaconda3/lib/python3.9/site-packages (from patchify) (1.21.5)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for cv2\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_291843/877787353.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "!pip install patchify\n",
    "!pip install cv2\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "from skimage.measure import block_reduce\n",
    "from patchify import patchify\n",
    "from patchify import unpatchify\n",
    "from xml.dom.minidom import parse\n",
    "import re\n",
    "from PIL import Image\n",
    "from google.colab.patches import cv2_imsho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TR8PA3hkxhbt"
   },
   "source": [
    "**Defining Useful Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fC-6dxJmxlWV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/akshat/team45submission/tmc_input\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIR = os.path.join(os.getcwd(), 'tmc_input')\n",
    "print(INPUT_DIR)\n",
    "filename = \"tmc_ch2\"\n",
    "PATCH_SIZE = 16\n",
    "DOWNSAMPLE_RES = 4\n",
    "SAMPLE_METHOD = \"bicubic\"\n",
    "num_im = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKdXsgVoxAfk"
   },
   "source": [
    "**Defining Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JboksJQvw8MU"
   },
   "outputs": [],
   "source": [
    "def get_shape(xml_filename):\n",
    "    dom = parse(xml_filename)\n",
    "    name = dom.getElementsByTagName('elements')\n",
    "    print (name[0].firstChild.nodeValue)\n",
    "    print (name[1].firstChild.nodeValue)\n",
    "    return (int(name[0].firstChild.nodeValue), int(name[1].firstChild.nodeValue))\n",
    "\n",
    "def check2(im):\n",
    "    k=0\n",
    "    for i in range(1, 64):\n",
    "        for j in range(1, 64):\n",
    "            if im[i][j]==255:\n",
    "                k+=1\n",
    "    return k\n",
    "\n",
    "def get_patches(image):\n",
    "    patches = patchify(image, (PATCH_SIZE,PATCH_SIZE), step=PATCH_SIZE)\n",
    "    print(patches.shape)\n",
    "    return patches\n",
    "\n",
    "def isValid(img, x=0.9):\n",
    "    return (np.corrcoef(cv.medianBlur(img, 3).ravel(), img.ravel())[0][1] > x)\n",
    "\n",
    "def is_monochromatic_image(img):\n",
    "    extr = Image.fromarray(img).getextrema()\n",
    "    a = 0\n",
    "    for i in extr:\n",
    "        if isinstance(i, tuple):\n",
    "            a += abs(i[0] - i[1])\n",
    "        else:\n",
    "            a = abs(extr[0] - extr[1])\n",
    "            break\n",
    "    return a == 0\n",
    "\n",
    "def save(patches):\n",
    "    num_im=0\n",
    "    path = INPUT_DIR + \"patches\"\n",
    "    isExist = os.path.exists(path)\n",
    "    if not isExist:\n",
    "        os.makedirs(path)\n",
    "    for i in range(patches.shape[0]):\n",
    "        for j in range(3, patches.shape[1]):\n",
    "            if not(is_monochromatic_image(patches[i][j])):\n",
    "                plt.imsave(path + f\"{i}_{j}.png\", patches[i][j]*255, cmap='gray')\n",
    "                num_im += 1\n",
    "    print('Done')\n",
    "\n",
    "def get_noises(patches):\n",
    "    patch_noise = []\n",
    "\n",
    "    for i in range(patches.shape[0]):\n",
    "        patch_noise.append([])\n",
    "        for j in range(patches.shape[1]):\n",
    "            patch_noise[-1].append(np.corrcoef(cv.medianBlur(patches[i][j], 3).ravel(),patches[i][j].ravel())[0][1])\n",
    "    return patch_noise\n",
    "\n",
    "def show_plots(patches):\n",
    "    noises = get_noises(patches)\n",
    "    noises = np.array(noises)\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.hist(noises)\n",
    "    plt.title('Patch Noises')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.imshow(noises,  cmap='hot', interpolation='nearest')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "rL5f9mkySOLj",
    "outputId": "a314c857-89a5-4fc1-aa27-78d1107fec53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/akshat/team45submission/tmc_input/tmc_ch2.tif\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_291843/2133166858.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "input_image = filename + '.tif'\n",
    "image_path = os.path.join(INPUT_DIR, input_image)\n",
    "print(image_path)\n",
    "img = cv.imread(input_image, -1)\n",
    "image = np.asarray(img)\n",
    "print(img.shape)\n",
    "patches = get_patches(image)\n",
    "save(patches)\n",
    "plt.imshow(img, cmap = \"gray\")\n",
    "plt.show()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBS6I0z03-lQ"
   },
   "source": [
    "**Creating High Resolution Images Out of the Patches**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucZW9_9nCN5W"
   },
   "source": [
    "Writing on some files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2LQWJ36ACRG-",
    "outputId": "1190c0c4-d0e9-4d52-dcf4-b428d5e66bbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /content/HAT/options/test/HAT-L_SRx16_config.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile /content/HAT/options/test/HAT-L_SRx16_config.yml\n",
    "\n",
    "name: HAT-L_SRx16\n",
    "model_type: HATModel\n",
    "scale: 16\n",
    "num_gpu: 1  # set num_gpu: 0 for cpu mode\n",
    "manual_seed: 0\n",
    "\n",
    "datasets:\n",
    "  test_1:  # the 1st test dataset\n",
    "    name: Set5\n",
    "    type: PairedImageDataset\n",
    "    dataroot_gt: /content/drive/MyDrive/Test_Patches # PUT HR IMGS FOLDER PATH HERE\n",
    "    dataroot_lq: /content/drive/MyDrive/Test_Patches # PUT LR IMGS FOLDER PATH HERE\n",
    "    io_backend:\n",
    "      type: disk\n",
    "\n",
    "  # test_2:  # the 2nd test dataset\n",
    "  #   name: Set14\n",
    "  #   type: PairedImageDataset\n",
    "  #   dataroot_gt: ./datasets/Set14/GTmod4\n",
    "  #   dataroot_lq: ./datasets/Set14/LRbicx4\n",
    "  #   io_backend:\n",
    "  #     type: disk\n",
    "\n",
    "  # test_3:\n",
    "  #   name: Urban100\n",
    "  #   type: PairedImageDataset\n",
    "  #   dataroot_gt: ./datasets/urban100/GTmod4\n",
    "  #   dataroot_lq: ./datasets/urban100/LRbicx4\n",
    "  #   io_backend:\n",
    "  #     type: disk\n",
    "\n",
    "  # test_4:\n",
    "  #    name: BSDS100\n",
    "  #    type: PairedImageDataset\n",
    "  #    dataroot_gt: ./datasets/BSDS100/GTmod4\n",
    "  #    dataroot_lq: ./datasets/BSDS100/LRbicx4\n",
    "  #    io_backend:\n",
    "  #      type: disk\n",
    "\n",
    "  # test_5:\n",
    "  #     name: Manga109\n",
    "  #     type: PairedImageDataset\n",
    "  #     dataroot_gt: ./datasets/manga109/GTmod4\n",
    "  #     dataroot_lq: ./datasets/manga109/LRbicx4\n",
    "  #     io_backend:\n",
    "  #       type: disk\n",
    "\n",
    "# network structures\n",
    "network_g:\n",
    "  type: HAT\n",
    "  upscale: 16\n",
    "  in_chans: 3\n",
    "  img_size: 16\n",
    "  window_size: 4\n",
    "  compress_ratio: 3\n",
    "  squeeze_factor: 30\n",
    "  conv_scale: 0.01\n",
    "  overlap_ratio: 0.5\n",
    "  img_range: 1.\n",
    "  depths: [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
    "  embed_dim: 180\n",
    "  num_heads: [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
    "  mlp_ratio: 2\n",
    "  upsampler: 'pixelshuffle'\n",
    "  resi_connection: '1conv'\n",
    "\n",
    "\n",
    "# path\n",
    "path:\n",
    "  pretrain_network_g: # PUT MODEL PATH HERE\n",
    "  strict_load_g: true\n",
    "  param_key_g: 'params_ema'\n",
    "\n",
    "# validation settings\n",
    "val:\n",
    "  save_img: true\n",
    "  suffix: ~  # add suffix to saved images, if None, use exp name\n",
    "\n",
    "  metrics:\n",
    "    psnr: # metric name, can be arbitrary\n",
    "      type: calculate_psnr\n",
    "      crop_border: 4\n",
    "      test_y_channel: true\n",
    "    ssim:\n",
    "      type: calculate_ssim\n",
    "      crop_border: 4\n",
    "      test_y_channel: true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3hKwNnYCtcO"
   },
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6EMcHlCnCmze",
    "outputId": "c1f4095a-ca9e-4c46-d2f7-099ecd18e669"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disable distributed.\n",
      "2023-02-08 12:44:25,531 INFO: \n",
      "                ____                _       _____  ____\n",
      "               / __ ) ____ _ _____ (_)_____/ ___/ / __ \\\n",
      "              / __  |/ __ `// ___// // ___/\\__ \\ / /_/ /\n",
      "             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/\n",
      "            /_____/ \\__,_//____//_/ \\___//____//_/ |_|\n",
      "     ______                   __   __                 __      __\n",
      "    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /\n",
      "   / / __ / __ \\ / __ \\ / __  /  / /   / / / // ___// //_/  / /\n",
      "  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/\n",
      "  \\____/ \\____/ \\____/ \\____/  /_____/\\____/ \\___//_/|_|  (_)\n",
      "    \n",
      "Version Information: \n",
      "\tBasicSR: 1.3.4.9\n",
      "\tPyTorch: 1.13.1+cu116\n",
      "\tTorchVision: 0.14.1+cu116\n",
      "2023-02-08 12:44:25,531 INFO: \n",
      "  name: HAT-L_SRx16\n",
      "  model_type: HATModel\n",
      "  scale: 16\n",
      "  num_gpu: 1\n",
      "  manual_seed: 0\n",
      "  datasets:[\n",
      "    test_1:[\n",
      "      name: Set5\n",
      "      type: PairedImageDataset\n",
      "      dataroot_gt: /content/drive/MyDrive/Test_Patches\n",
      "      dataroot_lq: /content/drive/MyDrive/Test_Patches\n",
      "      io_backend:[\n",
      "        type: disk\n",
      "      ]\n",
      "      phase: test\n",
      "      scale: 16\n",
      "    ]\n",
      "  ]\n",
      "  network_g:[\n",
      "    type: HAT\n",
      "    upscale: 16\n",
      "    in_chans: 3\n",
      "    img_size: 16\n",
      "    window_size: 4\n",
      "    compress_ratio: 3\n",
      "    squeeze_factor: 30\n",
      "    conv_scale: 0.01\n",
      "    overlap_ratio: 0.5\n",
      "    img_range: 1.0\n",
      "    depths: [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "    embed_dim: 180\n",
      "    num_heads: [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "    mlp_ratio: 2\n",
      "    upsampler: pixelshuffle\n",
      "    resi_connection: 1conv\n",
      "  ]\n",
      "  path:[\n",
      "    pretrain_network_g: None\n",
      "    strict_load_g: True\n",
      "    param_key_g: params_ema\n",
      "    results_root: /content/HAT/results/HAT-L_SRx16\n",
      "    log: /content/HAT/results/HAT-L_SRx16\n",
      "    visualization: /content/HAT/results/HAT-L_SRx16/visualization\n",
      "  ]\n",
      "  val:[\n",
      "    save_img: True\n",
      "    suffix: None\n",
      "    metrics:[\n",
      "      psnr:[\n",
      "        type: calculate_psnr\n",
      "        crop_border: 4\n",
      "        test_y_channel: True\n",
      "      ]\n",
      "      ssim:[\n",
      "        type: calculate_ssim\n",
      "        crop_border: 4\n",
      "        test_y_channel: True\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "  dist: False\n",
      "  rank: 0\n",
      "  world_size: 1\n",
      "  auto_resume: False\n",
      "  is_train: False\n",
      "\n",
      "2023-02-08 12:44:25,608 INFO: Dataset [PairedImageDataset] - Set5 is built.\n",
      "2023-02-08 12:44:25,608 INFO: Number of test images in Set5: 1555\n",
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "2023-02-08 12:44:26,670 INFO: Network [HAT] is created.\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/HAT/hat/test.py\", line 11, in <module>\n",
      "    test_pipeline(root_path)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/basicsr/test.py\", line 35, in test_pipeline\n",
      "    model = build_model(opt)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/basicsr/models/__init__.py\", line 27, in build_model\n",
      "    model = MODEL_REGISTRY.get(opt['model_type'])(opt)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/basicsr/models/sr_model.py\", line 23, in __init__\n",
      "    self.net_g = self.model_to_device(self.net_g)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/basicsr/models/base_model.py\", line 94, in model_to_device\n",
      "    net = net.to(self.device)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 989, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 987, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: No CUDA GPUs are available\n"
     ]
    }
   ],
   "source": [
    "!python /content/HAT/hat/test.py -opt /content/HAT/options/test/HAT-L_SRx16_config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNKdOI_N25QP"
   },
   "source": [
    "**Joining the Patches Back**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QXD9Iis329qp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/akshat/team45submission/HAT/results/HAT_SRx4/visualization/\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_291843/2873766156.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HAT/results/HAT_SRx4/visualization/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrec_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), 'HAT/results/HAT_SRx4/visualization/')\n",
    "print(path)\n",
    "rec_arr = np.empty((int(patches.shape[0]), int(patches.shape[1]), PATCH_SIZE, PATCH_SIZE))\n",
    "for file_name in os.listdir(path):\n",
    "    file = path + file_name\n",
    "    if os.path.isfile(file):\n",
    "        temp = re.findall(r'\\d+', file_name)\n",
    "        res = list(map(int, temp))\n",
    "        rec_arr[int(res[0])][int(res[1])] = cv.imread(file)[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "pom7h2uy3L8m",
    "outputId": "e8b13f59-385c-400d-ae46-91c9aa13f3b3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unpatchify' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_291843/1815634507.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrec_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpatchify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mPATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mPATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'upscaled_output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unpatchify' is not defined"
     ]
    }
   ],
   "source": [
    "rec_im = unpatchify(patches, (patches.shape[0]*PATCH_SIZE, patches.shape[1]*PATCH_SIZE))\n",
    "plt.imshow(rec_im, cmap = \"gray\")\n",
    "plt.show()\n",
    "output_path = os.path.join(os.getcwd(), 'upscaled_output')\n",
    "print(output_path)\n",
    "plt.imsave('/content/gdrive/MyDrive/joined.png', rec_im, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6C5wjhdGq4U"
   },
   "source": [
    "**Converting the upsampled .png to .tif file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "AlLw2KgJGhrq"
   },
   "outputs": [],
   "source": [
    "import gdal\n",
    "import subprocess\n",
    "from subprocess import PIPE\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "ObReW3KXHBwW"
   },
   "outputs": [],
   "source": [
    "XML_PATH = INPUT_PATH + INPUT\n",
    "OUTPUT_IMG_NAME = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "I8rO0i3YHN6i",
    "outputId": "63641e8e-3716-492a-96d1-6567fe88bb4e"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-13389da5701c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{XML_PATH+'.xml'}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mBs_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBs_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Axis_Array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/tmc-intersecting/ch2_tmc_ndn_20220221T1109281684_d_oth_d18.xml'"
     ]
    }
   ],
   "source": [
    "with open(f\"{XML_PATH+'.xml'}\", 'r') as f:\n",
    "    data = f.read()\n",
    "Bs_data = BeautifulSoup(data, \"xml\")\n",
    "data = Bs_data.find_all('Axis_Array')\n",
    "for item in data:\n",
    "    if item.axis_name.string == 'Line':\n",
    "        height = int(item.elements.string)*16\n",
    "    if item.axis_name.string == 'Sample':\n",
    "        width = int(item.elements.string)*16\n",
    "data = Bs_data.find('isda:Corrected_Corner_Coordinates').find_all()\n",
    "lats, longs = [], []\n",
    "for index, item in enumerate(data):\n",
    "    if index%2:\n",
    "        longs.append(float(item.string))\n",
    "    else:\n",
    "        lats.append(float(item.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ks_SNIkPKMyR"
   },
   "outputs": [],
   "source": [
    "result = subprocess.run(f\"gdal_translate -ot Int16 -of GTiff -a_srs .\\wkt.prj -gcp 0 0 {longs[0]} {lats[0]} -gcp {width} 0 {longs[1]} {lats[1]} -gcp 0 {height} {longs[2]} {lats[2]} -gcp {width} {height} {longs[3]} {lats[3]} {input_img_name+'.png'} {output_img_name+'.tif'}\", stdout=PIPE, stderr=PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad75tc6AJMI0"
   },
   "outputs": [],
   "source": [
    "print(result.stdout)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
